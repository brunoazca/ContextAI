
//
//  LLMManager.swift
//  Teste Context AI
//
//  Created by Bruno Azambuja Carvalho on 15/10/25.
//

import Foundation
import Combine

// MARK: - Assistente Action Model
struct AssistenteAction {
    let id: String
    let name: String
    let description: String
    let keywords: [String]
}
// MARK: - LLM Manager

@MainActor
class LLMManager: ObservableObject {
    
    @Published var isLoading = false
    @Published var lastError: String?
    @Published var lastResponse: String = ""
    
    let provider: AIModelProvider
    private let contextManager: ContextManager
    
    enum LLMError: Error, LocalizedError {
        case providerUnavailable
        
        var errorDescription: String? {
            switch self {
            case .providerUnavailable:
                return "Nenhum provedor de IA dispon√≠vel."
            }
        }
    }
    
    init(provider: AIModelProvider? = nil, contextManager: ContextManager? = nil) {
        if let provider = provider {
            self.provider = provider
        } else {
            // Usa o HybridAIProvider com Foundation Models como padr√£o
            self.provider = HybridAIProvider()
        }
        
        self.contextManager = contextManager ?? ContextManager()
    }
    
    /// M√©todo para trocar o provider do LLM
    func switchProvider(to type: HybridAIProvider.ProviderType) {
        if let hybridProvider = provider as? HybridAIProvider {
            hybridProvider.selectProvider(type)
        }
    }
    
    // MARK: - Public Methods
    
    /// Processa texto com o modelo LLM
    func processText(_ prompt: String, model: String? = nil) async throws -> String {
        isLoading = true
        lastError = nil
        
        defer {
            isLoading = false
        }
        
        guard provider.isAvailable else {
            throw LLMError.providerUnavailable
        }
        do {
            print("ü§ñ LLMManager: Enviando prompt para o provedor de IA (\(prompt.count) caracteres)")
            let responseText = try await provider.generate(prompt: prompt)
            self.lastResponse = responseText
            
            print("ü§ñ LLMManager: Resposta recebida do LLM (\(responseText.count) caracteres)")
            
            // Salva a resposta no contexto para futuras refer√™ncias
            contextManager.addContext(responseText, source: "LLM Response", metadata: [
                "model": model ?? "default",
                "prompt_length": String(prompt.count),
                "response_length": String(responseText.count)
            ])
            
            print("ü§ñ LLMManager: Resposta salva no contexto para futuras refer√™ncias")
            
            return responseText
        } catch {
            print("‚ùå LLMManager: Erro no processamento: \(error.localizedDescription)")
            self.lastError = error.localizedDescription
            throw error
        }
    }
    
    /// Processa texto reconhecido pelo OCR com contexto espec√≠fico
    func processOCRText(_ recognizedText: String) async throws -> String {
        print("ü§ñ LLMManager: Processando texto OCR com Foundation Models")
        
        // Primeiro, analisa o texto OCR com Foundation Models para entender o que o usu√°rio est√° fazendo
        let activityAnalysis = try await analyzeOCRWithFoundationModels(recognizedText)
        
        // Salva a an√°lise da atividade no contexto (n√£o o texto bruto do OCR)
        contextManager.addContext(activityAnalysis, source: "OCR Analysis", metadata: [
            "text_length": String(recognizedText.count),
            "word_count": String(recognizedText.components(separatedBy: .whitespaces).count),
            "original_ocr": String(recognizedText.prefix(200)) // Mant√©m uma amostra do OCR original
        ])
        
        // Busca contexto hist√≥rico relevante
        let historicalContext = contextManager.generateContextForLLM(currentContent: activityAnalysis)
        
        let availableActionsContext = generateAvailableActionsContext()
        
        let prompt = """
        Com base na an√°lise da atividade atual do usu√°rio e no contexto hist√≥rico, forne√ßa uma an√°lise √∫til e sugest√µes pr√°ticas focadas em a√ß√µes execut√°veis.
        
        \(availableActionsContext)
        
        ATIVIDADE ATUAL DO USU√ÅRIO:
        \(activityAnalysis)
        
        CONTEXTO HIST√ìRICO:
        \(historicalContext)
        
        INSTRU√á√ïES:
        1. Analise a atividade atual do usu√°rio
        2. Identifique se alguma das a√ß√µes dispon√≠veis √© relevante
        3. Se relevante, sugira a a√ß√£o espec√≠fica com detalhes pr√°ticos
        4. Se nenhuma a√ß√£o for relevante, responda "Nenhuma a√ß√£o dispon√≠vel"
        5. Seja espec√≠fico sobre qual a√ß√£o e como execut√°-la
        6. Responda em portugu√™s brasileiro
        7. M√°ximo 3 frases
        """
        
        print("ü§ñ LLMManager: Enviando prompt para an√°lise de atividade com contexto hist√≥rico")
        return try await processText(prompt)
    }
    
    /// Processa texto com prompt customizado
    func processWithCustomPrompt(_ text: String, customPrompt: String) async throws -> String {
        // Salva o texto no contexto
        contextManager.addContext(text, source: "Custom Analysis", metadata: [
            "prompt_type": "custom",
            "prompt_length": String(customPrompt.count),
            "text_length": String(text.count)
        ])
        
        // Busca contexto hist√≥rico relevante
        let historicalContext = contextManager.generateContextForLLM(currentContent: text)
        
        let availableActionsContext = generateAvailableActionsContext()
        
        let fullPrompt = """
        \(customPrompt)
        
        \(availableActionsContext)
        
        \(historicalContext)
        
        Texto para an√°lise:
        \(text)
        """
        
        return try await processText(fullPrompt)
    }
    
    /// Processa prompt customizado usando apenas o contexto hist√≥rico (sem texto adicional)
    func processCustomPromptWithContext(_ customPrompt: String) async throws -> String {
        print("ü§ñ LLMManager: Processando prompt customizado com contexto hist√≥rico (sem captura)")
        print("ü§ñ LLMManager: Prompt: \(customPrompt)")
        
        // Busca contexto hist√≥rico relevante baseado no prompt
        let historicalContext = contextManager.generateContextForLLM(currentContent: customPrompt)
        
        print("ü§ñ LLMManager: Contexto hist√≥rico encontrado: \(historicalContext.count) caracteres")
        
        let availableActionsContext = generateAvailableActionsContext()
        
        let fullPrompt = """
        \(customPrompt)
        
        \(availableActionsContext)
        
        \(historicalContext)
        
        Use o contexto hist√≥rico acima para responder ao prompt. Se n√£o houver contexto relevante, indique isso na resposta.
        """
        
        print("ü§ñ LLMManager: Enviando prompt customizado com contexto hist√≥rico")
        return try await processText(fullPrompt)
    }
    
    // MARK: - Action Suggestion (raw text)
    /// Gera uma sugest√£o de a√ß√£o em TEXTO PURO priorizando contexto atual
    func generateSuggestionText(from recognizedText: String) async throws -> String {
        print("ü§ñ LLMManager: Gerando sugest√£o priorizando contexto atual (an√°lise a cada 7s)")
        
        // Primeiro, analisa o texto OCR com Foundation Models para entender o que o usu√°rio est√° fazendo
        let activityAnalysis = try await analyzeOCRWithFoundationModels(recognizedText)
        
        // Indexa a an√°lise da atividade no contexto (n√£o o texto bruto do OCR)
        contextManager.addContext(activityAnalysis, source: "OCR Analysis", metadata: [
            "text_length": String(recognizedText.count),
            "for_suggestion": "true",
            "timestamp": Date().timeIntervalSince1970.description,
            "original_ocr": String(recognizedText.prefix(200)) // Mant√©m uma amostra do OCR original
        ])
        
        // Busca apenas as 2 entradas mais recentes (incluindo a atual)
        let recentEntries = contextManager.findRecentEntriesForSuggestions(limit: 2)
        
        var contextString = ""
        if !recentEntries.isEmpty {
            contextString = "=== CONTEXTO ATUAL (M√°ximo 2 entradas mais recentes) ===\n\n"
            for (index, entry) in recentEntries.enumerated() {
                let dateFormatter = DateFormatter()
                dateFormatter.dateStyle = .short
                dateFormatter.timeStyle = .short
                
                contextString += "[\(index + 1)] \(entry.source) - \(dateFormatter.string(from: entry.timestamp))\n"
                contextString += "\(entry.content)\n\n"
            }
            contextString += "=== FIM DO CONTEXTO ATUAL ===\n\n"
        }
        
        let availableActionsContext = generateAvailableActionsContext()
        
        let prompt = """
        Voc√™ √© um assistente proativo com capacidades espec√≠ficas. Com base na atividade atual do usu√°rio, sugira APENAS a√ß√µes que voc√™ pode realmente executar.

        \(availableActionsContext)
        
        \(contextString)
        
        ATIVIDADE ATUAL (O que o usu√°rio est√° fazendo AGORA):
        \(activityAnalysis)
        
        INSTRU√á√ïES:
        - Analise a atividade atual do usu√°rio
        - Identifique se alguma das a√ß√µes dispon√≠veis √© relevante
        - Se relevante, sugira a a√ß√£o espec√≠fica com detalhes pr√°ticos
        - Se nenhuma a√ß√£o for relevante, responda "Nenhuma a√ß√£o dispon√≠vel"
        - Seja espec√≠fico sobre qual a√ß√£o e como execut√°-la
        - Responda em portugu√™s brasileiro
        - M√°ximo 2 frases
        """
        
        print("ü§ñ LLMManager: Enviando prompt para sugest√£o com atividade atual")
        let suggestion = try await processText(prompt).trimmingCharacters(in: .whitespacesAndNewlines)
        
        print("ü§ñ LLMManager: Sugest√£o gerada: \(String(suggestion.prefix(100)))...")
        
        return suggestion
    }
    
    /// Retorna o gerenciador de contexto para acesso externo
    var contextManagerInstance: ContextManager {
        return contextManager
    }
    
    // MARK: - Available Actions
    /// Lista de a√ß√µes que o assistente pode executar
    private let availableActions: [AssistenteAction] = [
        AssistenteAction(
            id: "send_email",
            name: "Enviar Email",
            description: "Enviar emails para contatos espec√≠ficos",
            keywords: ["email", "enviar", "mensagem", "contato", "comunicar"]
        ),
        AssistenteAction(
            id: "schedule_meeting",
            name: "Marcar Reuni√£o",
            description: "Agendar reuni√µes com pessoas ou grupos",
            keywords: ["reuni√£o", "agendar", "encontro", "meeting", "calend√°rio"]
        ),
        AssistenteAction(
            id: "schedule_activity",
            name: "Agendar Atividade",
            description: "Criar lembretes e agendar tarefas pessoais",
            keywords: ["lembrete", "tarefa", "atividade", "agendar", "planner"]
        ),
        AssistenteAction(
            id: "purchase_item",
            name: "Comprar Item",
            description: "Adicionar itens a listas de compras ou fazer compras online",
            keywords: ["comprar", "shopping", "lista", "item", "produto", "loja"]
        )
    ]
    
    /// Gera contexto das a√ß√µes dispon√≠veis para o prompt
    private func generateAvailableActionsContext() -> String {
        var context = "=== A√á√ïES DISPON√çVEIS ===\n"
        context += "O assistente pode executar APENAS as seguintes a√ß√µes:\n\n"
        
        for (index, action) in availableActions.enumerated() {
            context += "\(index + 1). \(action.name)\n"
            context += "   - \(action.description)\n"
            context += "   - Palavras-chave: \(action.keywords.joined(separator: ", "))\n\n"
        }
        
        context += "IMPORTANTE: Sugira APENAS a√ß√µes desta lista. Se nenhuma a√ß√£o for relevante, responda 'Nenhuma a√ß√£o dispon√≠vel'.\n"
        context += "=== FIM DAS A√á√ïES DISPON√çVEIS ===\n\n"
        
        return context
    }
    
    /// Analisa texto OCR usando Foundation Models para entender o que o usu√°rio est√° fazendo
    func analyzeOCRWithFoundationModels(_ ocrText: String) async throws -> String {
        print("ü§ñ LLMManager: Analisando OCR com Foundation Models")
        
        let prompt = """
        Analise o seguinte texto extra√≠do de uma captura de tela e forne√ßa um resumo conciso (m√°ximo 2-3 frases) do que o usu√°rio est√° fazendo atualmente. Seja espec√≠fico sobre a atividade, aplicativo ou tarefa sendo realizada.

        Texto da tela:
        \(ocrText)

        Resumo da atividade:
        """
        
        print("ü§ñ LLMManager: Enviando texto OCR para an√°lise com Foundation Models")
        let analysis = try await processText(prompt).trimmingCharacters(in: .whitespacesAndNewlines)
        
        print("ü§ñ LLMManager: An√°lise OCR conclu√≠da: \(String(analysis.prefix(100)))...")
        
        return analysis
    }
}
